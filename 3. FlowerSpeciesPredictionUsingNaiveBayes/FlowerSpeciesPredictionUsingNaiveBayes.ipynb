{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9dddf3f8",
   "metadata": {},
   "source": [
    "# Flower species prediction using naive bayes algorithm\n",
    "In this notebook, we will implement the Gaussian Naive Bayes classification algorithm. we will use GaussianNB to explore the Iris flower dataset and to predict flower species.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8faa04f",
   "metadata": {},
   "source": [
    "## Iris Flower Species Dataset\n",
    "In this tutorial we will use the Iris Flower Species Dataset.\n",
    "\n",
    "The Iris Flower Dataset involves predicting the flower species given measurements of iris flowers.\n",
    "\n",
    "It is a multiclass classification problem. The number of observations for each class is balanced. There are 150 observations with 4 input variables and 1 output variable. The variable names are as follows:\n",
    "\n",
    "* Sepal length in cm.\n",
    "* Sepal width in cm.\n",
    "* Petal length in cm.\n",
    "* Petal width in cm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54f04d4",
   "metadata": {},
   "source": [
    "## Gaussian Naive Bayes implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c87793e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def update_class_label_count(y, classes_):\n",
    "    classes_count_ = np.zeros((len(classes_), 1), dtype=int)\n",
    "    for i in range(len(classes_)):\n",
    "        classes_count_[i] = y[y == classes_[i]].shape[0]\n",
    "    return classes_count_\n",
    "\n",
    "\n",
    "def update_classes_prior_prob(classes_count_, sample_space_size):\n",
    "    priors = classes_count_ / float(sample_space_size)\n",
    "    return priors\n",
    "\n",
    "\n",
    "class GaussianNB:\n",
    "    \"\"\"\n",
    "    GaussianNB algorithm using gaussian probability density function.\n",
    "        Parameters\n",
    "        ----------\n",
    "        priors : array-like of shape (n_classes,)\n",
    "            Prior probabilities of the classes. If specified the priors are not adjusted according to the data.\n",
    "        var_smoothing : float, default=1e-9\n",
    "            Portion of the largest variance of all features that is added to variances for calculation stability.\n",
    "        verbose : bool, default=False\n",
    "            if True, print intermediate execution outputs for debug.\n",
    "\n",
    "        Attributes\n",
    "        -----------\n",
    "        class_count_ : ndarray of shape (n_classes,)\n",
    "            number of training samples observed in each class.\n",
    "        class_prior_ : ndarray of shape (n_classes,)\n",
    "            probability of each class.\n",
    "        classes_ : ndarray of shape (n_classes,)\n",
    "            class labels known to the classifier.\n",
    "        epsilon_ : float\n",
    "            absolute additive value to variances.\n",
    "        n_features_in_ : int\n",
    "            Number of features seen during fit.\n",
    "        feature_names_in_ : ndarray of shape (n_features_in_,)\n",
    "            Names of features seen during fit. Defined only when X has feature names that are all strings.\n",
    "        var_ : ndarray of shape (n_classes, n_features)\n",
    "            Variance of each feature per class.h'\n",
    "        theta_ : ndarray of shape (n_classes, _features)\n",
    "            mean of each feature per class.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, priors=None, var_smoothing=1e-9, verbose=False):\n",
    "        self.priors = priors\n",
    "        self.var_smoothing = var_smoothing\n",
    "        self.verbose = verbose\n",
    "        self.class_count_ = None\n",
    "        self.class_prior_ = None\n",
    "        self.classes_ = None\n",
    "        self.epsilon_ = None\n",
    "        self.n_features_in_ = None\n",
    "        self.feature_names_in_ = None\n",
    "        self.var_ = None\n",
    "        self.theta_ = None\n",
    "\n",
    "    def update_mean_variance(self, X, y):\n",
    "        var_ = []\n",
    "        theta_ = []\n",
    "\n",
    "        for i in range(len(self.class_count_)):\n",
    "            class_label_data = X[y == self.classes_[i]]\n",
    "            var_.append(class_label_data.var(axis=0))\n",
    "            theta_.append(class_label_data.mean(axis=0))\n",
    "\n",
    "        self.var_ = var_\n",
    "        self.theta_ = theta_\n",
    "\n",
    "    def fit(self, X: pd.DataFrame, y):\n",
    "        self.classes_ = np.unique(y)\n",
    "        self.class_count_ = update_class_label_count(y, self.classes_)\n",
    "\n",
    "        if self.verbose:\n",
    "            print(\"No. of unique labels in dataset=[{}] and labels_name=[{}]\".format(self.class_count_, self.classes_))\n",
    "\n",
    "        if self.priors is None:\n",
    "            self.priors = update_classes_prior_prob(self.class_count_, len(y))\n",
    "\n",
    "        if self.verbose:\n",
    "            print(\"Prior probabilities for class labels are: [{}]\".format(self.priors))\n",
    "\n",
    "        self.n_features_in_ = X.shape[1]\n",
    "        self.feature_names_in_ = X.columns\n",
    "\n",
    "        if self.verbose:\n",
    "            print(\"No. of features in training dataset:[{}] and feature columns are: [{}]\".format(\n",
    "                self.n_features_in_, self.feature_names_in_))\n",
    "\n",
    "        self.update_mean_variance(X, y)\n",
    "\n",
    "    def _joint_log_likelihood(self, X):\n",
    "        joint_log_likelihood = []\n",
    "        for i in range(len(self.classes_)):\n",
    "            class_i_log_prob = np.log(self.priors[i])\n",
    "            x_ij_log_prob = -0.5 * np.sum(np.log(2 * np.pi * self.var_[i]))\n",
    "            x_ij_log_prob -= 0.5 * np.sum(np.square((X - self.theta_[i])) / self.var_[i], axis=1)\n",
    "            joint_log_likelihood.append(class_i_log_prob + x_ij_log_prob)\n",
    "\n",
    "        print(joint_log_likelihood)\n",
    "        joint_log_likelihood = np.array(joint_log_likelihood).T\n",
    "        return joint_log_likelihood\n",
    "\n",
    "    def predict(self, X):\n",
    "        jll = self._joint_log_likelihood(X)\n",
    "        return self.classes_[np.argmax(jll, axis=1)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056ca874",
   "metadata": {},
   "source": [
    "## Read Iris flower dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e26c21ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('iris.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aa283e8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(149, 5)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08121144",
   "metadata": {},
   "source": [
    "## Setting target label and feature columns name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c25c98e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['5.1', '3.5', '1.4', '0.2'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    Iris-setosa\n",
       "1    Iris-setosa\n",
       "2    Iris-setosa\n",
       "3    Iris-setosa\n",
       "4    Iris-setosa\n",
       "Name: Iris-setosa, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_label = df.columns[-1]\n",
    "feature_columns = df.columns.drop(target_label)\n",
    "\n",
    "print(feature_columns)\n",
    "\n",
    "X = df[feature_columns]\n",
    "y = df[target_label]\n",
    "\n",
    "X.head()\n",
    "\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33117c5",
   "metadata": {},
   "source": [
    "## Unique class labels for target label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bda7d486",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Iris-setosa', 'Iris-versicolor', 'Iris-virginica'], dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff65ab94",
   "metadata": {},
   "source": [
    "## Fit Iris dataset to GaussianNB model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "40c01a4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of unique labels in dataset=[[[49]\n",
      " [50]\n",
      " [50]]] and labels_name=[['Iris-setosa' 'Iris-versicolor' 'Iris-virginica']]\n",
      "Prior probabilities for class labels are: [[[0.32885906]\n",
      " [0.33557047]\n",
      " [0.33557047]]]\n",
      "No. of features in training dataset:[4] and feature columns are: [Index(['5.1', '3.5', '1.4', '0.2'], dtype='object')]\n"
     ]
    }
   ],
   "source": [
    "clf = GaussianNB(verbose=True)\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98802aa",
   "metadata": {},
   "source": [
    "### Predict target labels for training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ed324c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0        0.383511\n",
      "1        0.112276\n",
      "2        0.079018\n",
      "3        0.897612\n",
      "4       -2.168871\n",
      "          ...    \n",
      "144   -418.945959\n",
      "145   -329.286506\n",
      "146   -367.544295\n",
      "147   -437.678722\n",
      "148   -321.544077\n",
      "Length: 149, dtype: float64, 0     -37.586200\n",
      "1     -40.427044\n",
      "2     -37.933423\n",
      "3     -40.445555\n",
      "4     -33.397232\n",
      "         ...    \n",
      "144   -16.065674\n",
      "145    -6.642753\n",
      "146    -9.245975\n",
      "147   -17.789772\n",
      "148    -5.312802\n",
      "Length: 149, dtype: float64, 0     -55.223377\n",
      "1     -57.729643\n",
      "2     -55.313407\n",
      "3     -56.698971\n",
      "4     -49.046264\n",
      "         ...    \n",
      "144    -2.016407\n",
      "145    -3.084734\n",
      "146    -1.517316\n",
      "147    -2.890781\n",
      "148    -2.559120\n",
      "Length: 149, dtype: float64]\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4028933c",
   "metadata": {},
   "source": [
    "### Prediction on current dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "83111bdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy =  0.959731543624161\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy = \", sum(y==y_pred) / len(y))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
